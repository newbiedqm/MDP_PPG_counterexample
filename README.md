# MDP_PPG_counterexample
Projected Policy Gradient method fails to converge to an global optimal policy
